import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error
import math
import pickle

# ==============================
# üîπ 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
# ==============================
data = np.load("../dataset/chess_data.npz")
X_train, X_test = data["X_train"], data["X_test"]
y_train, y_test = data["y_train"], data["y_test"]

# –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤
with open("../dataset/rating_norm.pkl", "rb") as f:
    norm = pickle.load(f)

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä—ã
X_train_tensor = torch.tensor(X_train, dtype=torch.long)
X_test_tensor = torch.tensor(X_test, dtype=torch.long)
y_train_tensor = torch.tensor(y_train, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test, dtype=torch.float32)

train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
test_dataset = TensorDataset(X_test_tensor, y_test_tensor)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64)

# ==============================
# üîπ 2. –ú–æ–¥–µ–ª—å BiLSTM
# ==============================
class ChessEloBiLSTM(nn.Module):
    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256, dropout=0.3):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True, num_layers=2)
        self.dropout = nn.Dropout(dropout)
        self.fc1 = nn.Linear(hidden_dim * 2, 128)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128, 1)

    def forward(self, x):
        x = self.embedding(x)
        _, (h, _) = self.lstm(x)
        h = torch.cat((h[-2], h[-1]), dim=1)  # –æ–±—ä–µ–¥–∏–Ω—è–µ–º –≤—ã—Ö–æ–¥—ã –¥–≤—É—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π
        h = self.dropout(h)
        h = self.relu(self.fc1(h))
        out = self.fc2(h)
        return out.squeeze(1)

# ==============================
# üîπ 3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
# ==============================
with open("../dataset/move_encoder.pkl", "rb") as f:
    encoder = pickle.load(f)

vocab_size = len(encoder.classes_)
model = ChessEloBiLSTM(vocab_size=vocab_size)

criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)

# ==============================
# üîπ 4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
# ==============================
EPOCHS = 20
train_losses = []

print("üöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...\n")

for epoch in range(EPOCHS):
    model.train()
    total_loss = 0.0
    for xb, yb in train_loader:
        pred = model(xb)
        loss = criterion(pred, yb)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    avg_loss = total_loss / len(train_loader)
    train_losses.append(avg_loss)
    print(f"Epoch {epoch + 1}/{EPOCHS} | Loss: {avg_loss:.4f}")

print("\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

# ==============================
# üîπ 5. –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
# ==============================
model.eval()
with torch.no_grad():
    preds = model(X_test_tensor).numpy()

# –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –∏ –º–µ—Ç–æ–∫
preds_real = preds * norm["std"] + norm["mean"]
y_real = y_test * norm["std"] + norm["mean"]

mae = mean_absolute_error(y_real, preds_real)
rmse = math.sqrt(mean_squared_error(y_real, preds_real))

print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–µ:")
print(f"MAE: {mae:.2f} ELO")
print(f"RMSE: {rmse:.2f} ELO")

# ==============================
# üîπ 6. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
# ==============================
plt.figure(figsize=(7, 4))
plt.plot(train_losses, label="Train Loss (MSE)")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("üìâ –ì—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
plt.legend()
plt.show()

# ==============================
# üîπ 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
# ==============================
torch.save(model.state_dict(), "elo_lstm_model.pth")
print("üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ elo_lstm_model.pth")
